{
  "skill_geometricDeepLearning": "When to use: When working with data that has inherent geometric structure, symmetries, or invariance requirements (such as 3D molecules, point clouds, spherical signals, or graphs) and standard Euclidean neural networks (CNNs/MLPs) fail to generalize across rotations, translations, or deformations. Apply this skill to design architectures that mathematically guarantee symmetry preservation (equivariance/invariance). Step-by-step: 1) Identify the symmetry group acting on your data (e.g., SE(3) for 3D rotation/translation, permutation group for graphs). 2) Select an appropriate feature representation (e.g., Irreducible Representations for SO(3), invariant scalars vs. equivariant vectors). 3) Replace standard linear layers with equivariant convolutions or tensor products that constrain weight sharing according to the group structure. 4) Use geometric nonlinearities (like gated activations or norm-based nonlinearities) that preserve the vector/tensor properties. 5) For global tasks, apply invariant aggregation (pooling) at the final layer; for local tasks, maintain equivariance throughout. Key insights: This subsumes skills like equivariant graph attention, tensor product optimization, and invariant architecture design.",
  "skill_physicsInformedDeepLearning": "When to use: When modeling physical systems governed by partial differential equations (PDEs), conservation laws, or geometric constraints (e.g., fluid dynamics, structural mechanics, climate modeling) where purely data-driven models violate physical validity or require excessive data. Use this to integrate physical knowledge directly into the learning process. Step-by-step: 1) Formulate the governing physical equations (residuals) of the system (e.g., Navier-Stokes, Eikonal equation). 2) Design the neural network to output the physical state variables (velocity, pressure) given spatiotemporal coordinates. 3) Compute derivatives of the outputs with respect to inputs using automatic differentiation (Autograd) to evaluate the PDE residuals. 4) Construct a composite loss function: Data Loss (fitting observations) + Physics Loss (minimizing PDE residuals) + Boundary/Initial Condition Loss. 5) Optionally, use hard constraints (ansatz) or coordinate transformations to enforce boundary conditions by construction. Key insights: This guides specific skills like PDE-constrained latent dynamics, soft contact modeling, and neural operator learning.",
  "skill_diffusionGenerativeModeling": "When to use: When generating high-dimensional, complex data distributions (images, molecules, trajectories) where mode coverage and sample quality are critical, and likelihood-based training is preferred over adversarial training. This framework unifies score matching, Langevin dynamics, and stochastic differential equations (SDEs) for generation. Step-by-step: 1) Define a forward diffusion process (SDE) that gradually corrupts clean data into noise over time $t$. 2) Train a time-dependent neural network (score model/denoiser) to estimate the noise component or the gradient of the log-density (score) at each noise level. 3) For conditional generation, inject guidance (classifier gradients or cross-attention context) into the score estimation. 4) Generate samples by solving the reverse-time SDE or Probability Flow ODE, starting from random noise and iteratively refining the sample using the learned score. 5) Apply techniques like 'Reflow' or 'Distillation' to accelerate the sampling process for deployment. Key insights: This abstracts specific skills like Tweedie's denoising, classifier-free guidance, and rectified flow training.",
  "skill_biLevelOptimizationStrategy": "When to use: When solving hierarchical learning problems where an 'outer' objective depends on the optimal solution of an 'inner' objective. This applies to meta-learning (learning to learn), hyperparameter optimization, adversarial training, and dataset distillation. Step-by-step: 1) Define the Inner Problem: Minimize a loss $L_{inner}$ with respect to parameters $\\theta$ (e.g., model weights). 2) Define the Outer Problem: Minimize a validation/meta loss $L_{outer}$ with respect to hyperparameters $\\lambda$ (e.g., learning rates, data weights, architectures), assuming $\\theta$ is optimal for $\\lambda$. 3) Approximate the dependency of $\\theta^*$ on $\\lambda$ either by differentiating through the optimization path (unrolling SGD) or using the Implicit Function Theorem (Neumann series/Conjugate Gradient). 4) Compute the meta-gradient $\\nabla_\\lambda L_{outer}$ and update $\\lambda$. 5) Update $\\theta$ using the new $\\lambda$ and repeat. Key insights: This framework organizes skills like end-task aware meta-learning, gradient-based hyperparameter tuning, and adversarial attack generation.",
  "skill_selfSupervisedRepresentationLearning": "When to use: When labeled data is scarce but unlabeled data is abundant, and you need to learn robust, transferable feature representations. This covers Contrastive Learning, Masked Image Modeling, and non-contrastive methods. Step-by-step: 1) Define a set of data augmentations or corruptions (views) that preserve the semantic identity of the input (e.g., cropping, masking, color jitter). 2) Design an encoder architecture with a projection head to map inputs to a latent space. 3) For Contrastive methods: Pull embeddings of positive pairs (augmented views of same instance) together and push negative pairs (different instances) apart (InfoNCE). 4) For Masked methods: Predict/reconstruct missing parts of the input from the visible parts (MSE/Cross-Entropy). 5) For Non-Contrastive methods: Minimize distance between positive pairs while enforcing variance/decorrelation constraints to prevent collapse. 6) Discard the projection/decoder heads and use the encoder for downstream tasks. Key insights: This generalizes skills like momentum contrast, masked autoencoding, and spectral regularization.",
  "skill_neuralAlgorithmicReasoning": "When to use: When the task requires learning robust algorithms or logical reasoning steps that must generalize to inputs of arbitrary size/complexity (out-of-distribution), where standard pattern matching fails. Step-by-step: 1) Abstract the problem into algorithmic primitives (e.g., sorting, pathfinding) or logical rules. 2) Represent the input data structurally (e.g., graphs for relational data, sequences for stacks). 3) Design the architecture to mimic the computational steps of the target algorithm (algorithmic alignment), often using recurrent GNNs or shared-weight layers to iterate processing. 4) Use supervisory signals at intermediate execution steps (not just final output) to enforce the correct reasoning trace. 5) Employ mechanisms like pointer networks or reliable memory access to handle variable-sized inputs. Key insights: This covers skills like dual algorithmic reasoning, algorithm reconstruction, and neuro-symbolic integration.",
  "skill_robustOptimizationAndAdversarialDefense": "When to use: When deploying models in environments with worst-case perturbations, adversaries, or strict safety constraints. It focuses on minimizing the maximum possible loss (Minimax) within a defined uncertainty set. Step-by-step: 1) Define the threat model or uncertainty set (e.g., $L_p$ norm balls around inputs, or parameter perturbations). 2) Formulate the training as a min-max game: Inner loop finds the worst-case perturbation maximizing the loss; Outer loop updates model parameters to minimize this robust loss. 3) For certification, use bound propagation techniques (IBP, Lipschitz bounds) to theoretically guarantee outputs stay within safe ranges. 4) Incorporate regularization terms (like gradient penalties) to smooth the loss landscape and improve stability. Key insights: This abstracts skills like adversarial training, certified robustness, and worst-case metric design.",
  "skill_offlineReinforcementLearning": "When to use: When learning control policies from fixed, pre-collected datasets without the ability to interact with the environment during training. Critical for safety-critical systems or when simulation is unavailable. Step-by-step: 1) Estimate the behavior policy (distribution of actions in the dataset) to understand data support. 2) Learn a Value function (Q-function) using Bellman updates, but apply conservatism (pessimism) to penalize out-of-distribution actions (actions not seen in data). 3) Constrain the learned policy to stay close to the behavior policy (e.g., via KL-divergence or support matching) to avoid 'hallucinating' high rewards for unknown actions. 4) Use importance sampling or distribution correction if estimating metrics for a target policy different from the behavior policy. Key insights: This unifies skills like implicit pessimism, conservative Q-learning (CQL), and decision transformers.",
  "skill_neuroSymbolicReasoning": "When to use: When a problem requires both the perceptual flexibility of neural networks (handling noisy, unstructured data) and the precision/interpretability of symbolic logic (handling rules, math, constraints). Step-by-step: 1) Decompose the system into a Neural Module (perception/pattern matching) and a Symbolic Module (reasoning/execution). 2) Design an interface layer: converting neural outputs into discrete symbols (concepts) or differentiable approximations (soft logic). 3) Use the Symbolic Module to execute logical rules, programs, or arithmetic on the extracted symbols. 4) Train end-to-end (via gradients through soft logic) or separately (via REINFORCE or supervision) to optimize both perception and reasoning accuracy. Key insights: This abstracts skills like neuro-symbolic prompt construction, logic constraint integration, and program synthesis.",
  "skill_domainGeneralizationAndAdaptation": "When to use: When a model trained on source domains must perform well on unseen target domains with different statistics (covariate shift, label shift). Step-by-step: 1) Identify the type of distribution shift (e.g., style change, spurious correlation). 2) For Generalization (Zero-shot): Learn invariant features by minimizing the discrepancy between source domains (e.g., using MMD or adversarial domain discriminators) or by randomizing domain-specific features (data augmentation). 3) For Adaptation (Few-shot/Unsupervised): Fine-tune specific model parameters (like batch norm statistics or biases) on target data, or align target features to the source distribution using pseudo-labeling or entropy minimization. 4) Use causal analysis to separate stable causal features from unstable environmental features. Key insights: This covers skills like invariant risk minimization, test-time adaptation, and source-free domain adaptation.",
  "skill_distributedFederatedLearning": "When to use: When training models on decentralized data sources (clients/edge devices) where privacy, communication bandwidth, or data heterogeneity (Non-IID) are bottlenecks. Step-by-step: 1) Initialize a global model on the server. 2) Distribute the model to a subset of clients. 3) Perform local training on clients using private data (SGD/Adam). 4) Send model updates (gradients or weights) back to the server, optionally applying compression (quantization/sparsification) or differential privacy (noise addition). 5) Aggregation: Combine client updates on the server (e.g., FedAvg) while handling drift caused by heterogeneous data (using proximal terms or adaptive server optimizers). 6) Repeat until convergence. Key insights: This includes skills like adaptive server extrapolation, robust federated deployment, and gradient diversity analysis.",
  "skill_parameterEfficientModelAdaptation": "When to use: When adapting large pre-trained 'foundation' models (LLMs, ViTs) to specific downstream tasks without the computational cost of full fine-tuning. Step-by-step: 1) Freeze the bulk of the pre-trained model parameters. 2) Introduce a small set of trainable parameters: Adapters (bottleneck layers between existing layers), Prompt/Prefix Tuning (learnable input tokens), or Low-Rank Adaptation (LoRA - decomposing weight updates into low-rank matrices). 3) Train only these new parameters on the task-specific dataset. 4) Optionally, use techniques like weight averaging (model soup) or dynamic routing to combine multiple adaptations. Key insights: This covers skills like minimalist adapter co-training, prompt engineering, and efficient fine-tuning protocols.",
  "skill_retrievalAugmentedGenerationStrategy": "When to use: When generative models (LLMs) need to access up-to-date, proprietary, or vast external knowledge bases that cannot be encoded in their weights (hallucination reduction). Step-by-step: 1) Index the external knowledge base: Chunk documents and encode them into a vector database using a dense retriever model. 2) Query Processing: Encode the user input query and perform a similarity search (Nearest Neighbor) to retrieve the top-k relevant context chunks. 3) Context Integration: Augment the input prompt with the retrieved chunks (concatenation) or fuse embeddings in intermediate layers (cross-attention). 4) Generation: Feed the augmented context to the generator model to produce the answer grounded in the retrieved evidence. Key insights: This unifies skills like task-agnostic retrieval augmentation, nearest neighbor proxy training, and structured knowledge standardization.",
  "skill_implicitNeuralRepresentationLearning": "When to use: When representing continuous signals (images, 3D shapes, sound, fields) efficiently, independent of discrete grid resolution. Step-by-step: 1) Define the object as a continuous function $f(x,y,z) \\to v$ (mapping coordinates to values like color/density). 2) Parameterize this function with a Multi-Layer Perceptron (MLP). 3) Use positional encodings (Fourier features) to map low-dimensional coordinates to high dimensions, enabling the network to learn high-frequency details. 4) Train the network by sampling coordinates and minimizing the reconstruction error against the signal observations (or solving PDEs). 5) For modulation/dynamics, condition the network on latent codes (Hypernetworks) to represent families of signals or time evolution. Key insights: This covers skills like Fourier positional encoding, coordinate-based INRs, and functional weight remapping.",
  "skill_curriculumAndActiveLearning": "When to use: When labeled data is expensive (Active Learning) or the task is too complex to learn directly (Curriculum Learning). It focuses on optimizing the *order* and *selection* of training data. Step-by-step: 1) Define a scoring metric for data utility: Uncertainty (entropy/variance), Difficulty (loss magnitude), or Diversity (feature distance). 2) For Active Learning: Iteratively select the top-k highest scoring samples from the unlabeled pool for annotation and retraining. 3) For Curriculum Learning: Sort the training data by difficulty (easy to hard). Start training on the easy subset and progressively introduce harder samples as performance plateaus. 4) Use feedback loops to dynamically adjust the curriculum or selection criteria based on model learning dynamics. Key insights: This subsumes skills like hierarchical active selection, competence-based data curation, and self-paced learning.",
  "skill_theoreticalDeepLearningAnalysis": "When to use: When you need to derive guarantees about convergence, generalization, or expressivity of deep learning models, moving beyond empirical trial-and-error. Step-by-step: 1) Define the model regime: Linear (NTK/Lazy) vs. Feature Learning (Rich/Mean-Field). 2) Analyze the optimization dynamics (Gradient Flow) to determine implicit biases (e.g., rank minimization, margin maximization). 3) Derive bounds: Generalization bounds using complexity measures (VC-dim, Rademacher, Norm-based), or Optimization bounds using landscape geometry (PL-inequality, convexity). 4) Use limit analysis (infinite width/depth) to simplify dynamics into solvable differential equations. Key insights: This covers skills like implicit bias analysis, neural tangent kernel derivation, and sandwich bounding.",
  "skill_causalRepresentationLearning": "When to use: When building models that must robustly identify cause-and-effect relationships rather than spurious correlations, enabling interventions and counterfactual reasoning. Step-by-step: 1) Model the system using a Structural Causal Model (SCM) or Directed Acyclic Graph (DAG). 2) Distinguish between invariant causal mechanisms (stable across environments) and spurious associations. 3) Use interventions (do-calculus) or environmental diversity to discover the causal graph. 4) Learn representations that satisfy conditional independence constraints implied by the causal structure (disentanglement). 5) Optimize for Invariant Risk Minimization (IRM) to find predictors that are optimal across all interventional distributions. Key insights: This unifies skills like causal mediation analysis, front-door prompting, and causal shift diagnosis.",
  "skill_graphNeuralNetworkDesign": "When to use: When data is structured as a set of entities and relationships (social networks, molecules, meshes) and you need to predict properties of nodes, edges, or the whole graph. Step-by-step: 1) Define the graph topology (adjacency) and input features. 2) Design the Message Passing mechanism: how nodes aggregate information from neighbors (e.g., sum/mean/max pooling, attention). 3) Incorporate structural inductive biases: positional encodings for topology, edge features for relations, or hierarchical pooling for long-range interactions. 4) Handle scalability issues (for large graphs) using sampling (NeighborSampling), coarsening, or spectral approximations. 5) Ensure appropriate invariance (permutation invariance) or equivariance depending on the task. Key insights: This covers skills like message passing, spectral graph augmentation, and graph topology consistency.",
  "skill_fairnessAndPrivacyPreservingML": "When to use: When developing AI systems that must comply with ethical/legal standards regarding non-discrimination (Fairness) and data protection (Privacy). Step-by-step: 1) For Fairness: Identify protected attributes. Measure bias using metrics like Equalized Odds or Demographic Parity. Mitigate bias via pre-processing (reweighting), in-processing (adversarial debiasing, constraint optimization), or post-processing (threshold adjustment). 2) For Privacy: Define the privacy budget (epsilon). Apply Differential Privacy (DP) mechanisms, typically DP-SGD, which involves clipping per-sample gradients to bound sensitivity and adding calibrated noise to the aggregate update. 3) Evaluate the trade-off between utility (accuracy) and privacy/fairness constraints. Key insights: This abstracts skills like adaptive global scaling, adversarial debiasing, and fairness metric selection.",
  "skill_structuredOutputPrediction": "When to use: When the model output is not a simple class or scalar, but a complex structured object (e.g., a sequence, a tree, a matching, a code program) where dependencies between output elements must be modeled. Step-by-step: 1) Define the output space constraints and dependencies (e.g., grammar rules, bi-partite matching constraints). 2) Use autoregressive models (like Transformers) to generate elements sequentially conditioned on history, or non-autoregressive models with iterative refinement. 3) Apply structural losses (e.g., connectionist temporal classification, graph edit distance, optimal transport cost) rather than simple pointwise error. 4) Use inference techniques like beam search or constrained decoding to find the most likely valid structure. Key insights: This covers skills like hierarchical bipartite matching, permutation equivalent modeling, and program synthesis."
}